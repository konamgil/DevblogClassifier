{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Code Generator\n",
    "- jupyter에서 작업한 내용을 .py 파일로 쉽게 내보내기 위해 magic command 이용\n",
    "- 첫 줄의 %%writefile을 주석처리 하지 않으면 해당 셀 내용을 `name.py` 파일로 export\n",
    "- 첫 줄의 %%writefile을 주석처리하면 jupyter에서 실행됨\n",
    "- 코딩을 .py파일이 아닌 jupyter에서 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flag.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from document import Document\n",
    "from analysis import Analysis\n",
    "from word_vector import WordVector\n",
    "from classifier import Classifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def train(epochs=10,\n",
    "          batch_size=100,\n",
    "          validation_split=0.1,\n",
    "          verbose=0,\n",
    "          checkpoint_path='./model/checkpoints'):\n",
    "    \"\"\"\n",
    "    classifier 학습\n",
    "    \n",
    "    - input\n",
    "    : epochs / int / 학습 횟수\n",
    "    : batch_size / int / 배치 사이즈\n",
    "    : validation_split / float / validation data ratio\n",
    "    : checkpoint_path / str / 학습 중간 결과물 저장 경로\n",
    "    \n",
    "    - export\n",
    "    : ./model/classifier.json (graph)\n",
    "    : ./model/classifier.h5 (weights)\n",
    "    \"\"\"\n",
    "    \n",
    "    # load data\n",
    "    data = getTrainData()\n",
    "    \n",
    "    # train\n",
    "    model = cf.train(data,\n",
    "                 checkpoint_path=checkpoint_path,\n",
    "                 epochs=epochs,\n",
    "                 batch_size=batch_size,\n",
    "                 validation_split=validation_split,\n",
    "                 verbose=verbose)\n",
    "    cf.showHistory()\n",
    "\n",
    "def getTrainData():\n",
    "    \"\"\"\n",
    "    라벨링 된 데이터를 임베딩하여 반환\n",
    "    \n",
    "    - return\n",
    "    : DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # 라벨링 된 데이터만 가져오기\n",
    "    data = doc.getDocs(True) \n",
    "    \n",
    "    # vectorization\n",
    "    data['vector'] = data.text.apply(lambda x: wv.vectorization(wv_model, x))\n",
    "    return data\n",
    "\n",
    "def predict(text, criterion=0.5):\n",
    "    \"\"\"\n",
    "    개발관련 문서여부 반환\n",
    "    \n",
    "    - input\n",
    "    : text / str / 확인하려는 문서 내용 (영어 또는 한글이 포함되어있어야함)\n",
    "    : criterion / float / 개발관련 문서 판단 기준\n",
    "    \n",
    "    - return\n",
    "    : boolean / 개발문서 여부\n",
    "    : float / 1에 가까울수록 개발관련 문서\n",
    "    \"\"\"\n",
    "    data = doc.preprocessing(pd.DataFrame([{\n",
    "        'title': text,\n",
    "        'description': '',\n",
    "        'tags': []\n",
    "    }]))\n",
    "    data = data.text.apply(lambda x: wv.vectorization(wv_model, x)).tolist()\n",
    "\n",
    "    if len(data) == 0:\n",
    "        print('text is not valid')\n",
    "        return\n",
    "    data = np.array(data)\n",
    "    confidence = round(model.predict(data)[0][1], 3)\n",
    "    is_dev_doc = confidence > criterion\n",
    "    return is_dev_doc, confidence\n",
    "\n",
    "def getDataAnalysis():\n",
    "    \"\"\"\n",
    "    가지고있는 전체 데이터 분석\n",
    "    : label 별 수량\n",
    "    : 문장 길이 histogram\n",
    "    : WordCloud \n",
    "    \"\"\"\n",
    "    # 학습 데이터 분석\n",
    "    Analysis(doc.getDocs(labeled_only=False))\n",
    "    \n",
    "def getSimilarWords(text, topn=5):\n",
    "    \"\"\"\n",
    "    단어 임베딩 모델을 이용하여 주어진 단어와 유사도가 높은 단어를 반환\n",
    "    \n",
    "    - input\n",
    "    : text / str / 유사도를 구하려는 단어\n",
    "    : topn / int / 조회하려는 단어의 개수(유사도가 높은 순서로 자름)\n",
    "    \n",
    "    - return\n",
    "    : list / [(string : word, float : similarity)]\n",
    "    \"\"\"\n",
    "    # 유사 단어 조회\n",
    "    return wv.getSimilarWords(wv_model, text, topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./flags.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile ./flags.py\n",
    "import os, re\n",
    "from absl import flags\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "def create_flags():\n",
    "    f = flags\n",
    "\n",
    "    # flags\n",
    "    f.DEFINE_enum('wv_model', 'devblog', ['wiki', 'devblog'], 'word embedding model')\n",
    "    f.DEFINE_string('predict', None, \"sentence you want to predict. ex) 'hello world'\")\n",
    "    \n",
    "    # validation\n",
    "    f.register_validator('predict',\n",
    "                         lambda x: x != None,\n",
    "                         message=\"write the sentence you want to predict. ex) 'how to use python'\")\n",
    "\n",
    "    # require\n",
    "    f.mark_flag_as_required('predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./main.py\n",
    "from absl import app\n",
    "from flags import create_flags\n",
    "from document import Document\n",
    "from analysis import Analysis\n",
    "from word_vector import WordVector\n",
    "from classifier import Classifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "doc = Document()\n",
    "wv = WordVector()\n",
    "cf = Classifier()\n",
    "wv_model = wv.getWikiModel()\n",
    "model = cf.loadModel()\n",
    "\n",
    "def train(epochs=10,\n",
    "          batch_size=100,\n",
    "          validation_split=0.1,\n",
    "          verbose=0,\n",
    "          checkpoint_path='./model/checkpoints'):\n",
    "    \"\"\"\n",
    "    classifier 학습\n",
    "    \n",
    "    - input\n",
    "    : epochs / int / 학습 횟수\n",
    "    : batch_size / int / 배치 사이즈\n",
    "    : validation_split / float / validation data ratio\n",
    "    : checkpoint_path / str / 학습 중간 결과물 저장 경로\n",
    "    \n",
    "    - export\n",
    "    : ./model/classifier.json (graph)\n",
    "    : ./model/classifier.h5 (weights)\n",
    "    \"\"\"\n",
    "    \n",
    "    # load data\n",
    "    data = getTrainData()\n",
    "    \n",
    "    # train\n",
    "    model = cf.train(data,\n",
    "                 checkpoint_path=checkpoint_path,\n",
    "                 epochs=epochs,\n",
    "                 batch_size=batch_size,\n",
    "                 validation_split=validation_split,\n",
    "                 verbose=verbose)\n",
    "    cf.showHistory()\n",
    "\n",
    "def getTrainData():\n",
    "    \"\"\"\n",
    "    라벨링 된 데이터를 임베딩하여 반환\n",
    "    \n",
    "    - return\n",
    "    : DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # 라벨링 된 데이터만 가져오기\n",
    "    data = doc.getDocs(True) \n",
    "    \n",
    "    # vectorization\n",
    "    data['vector'] = data.text.apply(lambda x: wv.vectorization(wv_model, x))\n",
    "    return data\n",
    "\n",
    "def predict(text, criterion=0.5):\n",
    "    \"\"\"\n",
    "    개발관련 문서여부 반환\n",
    "    \n",
    "    - input\n",
    "    : text / str / 확인하려는 문서 내용 (영어 또는 한글이 포함되어있어야함)\n",
    "    : criterion / float / 개발관련 문서 판단 기준\n",
    "    \n",
    "    - return\n",
    "    : boolean / 개발문서 여부\n",
    "    : float / 1에 가까울수록 개발관련 문서\n",
    "    \"\"\"\n",
    "    data = doc.preprocessing(pd.DataFrame([{\n",
    "        'title': text,\n",
    "        'description': '',\n",
    "        'tags': []\n",
    "    }]))\n",
    "    data = data.text.apply(lambda x: wv.vectorization(wv_model, x)).tolist()\n",
    "\n",
    "    if len(data) == 0:\n",
    "        print('text is not valid')\n",
    "        return\n",
    "    data = np.array(data)\n",
    "    confidence = round(model.predict(data)[0][1], 3)\n",
    "    is_dev_doc = confidence > criterion\n",
    "    return is_dev_doc, confidence\n",
    "\n",
    "def getDataAnalysis():\n",
    "    \"\"\"\n",
    "    가지고있는 전체 데이터 분석\n",
    "    : label 별 수량\n",
    "    : 문장 길이 histogram\n",
    "    : WordCloud \n",
    "    \"\"\"\n",
    "    # 학습 데이터 분석\n",
    "    Analysis(doc.getDocs(labeled_only=False))\n",
    "    \n",
    "def getSimilarWords(text, topn=5):\n",
    "    \"\"\"\n",
    "    단어 임베딩 모델을 이용하여 주어진 단어와 유사도가 높은 단어를 반환\n",
    "    \n",
    "    - input\n",
    "    : text / str / 유사도를 구하려는 단어\n",
    "    : topn / int / 조회하려는 단어의 개수(유사도가 높은 순서로 자름)\n",
    "    \n",
    "    - return\n",
    "    : list / [(string : word, float : similarity)]\n",
    "    \"\"\"\n",
    "    # 유사 단어 조회\n",
    "    return wv.getSimilarWords(wv_model, text, topn)\n",
    "\n",
    "def main(_):\n",
    "    doc = Document()\n",
    "    wv = WordVector()\n",
    "    cf = Classifier()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_flags()\n",
    "    app.run(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## util.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./util.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile ./util.py\n",
    "import re\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def downloadByURL(url, output_path):\n",
    "    \"\"\"\n",
    "    HTTP 파일 다운로드\n",
    "    \n",
    "    - input\n",
    "    : url / str / 다운로드 받으려는 파일의 url\n",
    "    : output_path / str / 파일 저장 경로\n",
    "    \"\"\"\n",
    "    class DownloadProgressBar(tqdm):\n",
    "        def update_to(self, b=1, bsize=1, tsize=None):\n",
    "            if tsize is not None:\n",
    "                self.total = tsize\n",
    "            self.update(b * bsize - self.n)\n",
    "        \n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
    "\n",
    "def han2Jamo(str):\n",
    "    INITIALS = list(\"ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎ\")\n",
    "    MEDIALS = list(\"ㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣ\")\n",
    "    FINALS = list(\"_ㄱㄲㄳㄴㄵㄶㄷㄹㄺㄻㄼㄽㄾㄿㅀㅁㅂㅄㅅㅆㅇㅈㅊㅋㅌㅍㅎ\")\n",
    "    SPACE_TOKEN = \" \"\n",
    "    LABELS = sorted({SPACE_TOKEN}.union(INITIALS).union(MEDIALS).union(FINALS))\n",
    "\n",
    "    def check_hangle(char):\n",
    "        return 0xAC00 <= ord(char) <= 0xD7A3\n",
    "\n",
    "    def jamo_split(char):\n",
    "        assert check_hangle(char)\n",
    "        diff = ord(char) - 0xAC00\n",
    "        _m = diff % 28\n",
    "        _d = (diff - _m) // 28\n",
    "        return (INITIALS[_d // 21], MEDIALS[_d % 21], FINALS[_m])\n",
    "    \n",
    "    result = \"\"\n",
    "    for char in re.sub(\"\\\\s+\", SPACE_TOKEN, str.strip()):\n",
    "        if char == SPACE_TOKEN:\n",
    "            result += SPACE_TOKEN\n",
    "        elif check_hangle(char):\n",
    "            result += \"\".join(jamo_split(char))\n",
    "        else:\n",
    "            result += char\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./analysis.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile ./analysis.py\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "class Analysis():\n",
    "     \n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        데이터의 수량, 길이, WordCloud 분석\n",
    "        \n",
    "        - input\n",
    "        : data / DataFrame / documents.csv 데이터\n",
    "        \"\"\"\n",
    "        self.countAnalysis(data)\n",
    "        print()\n",
    "        self.textAnalysis(data)\n",
    "        print()\n",
    "        self.showWordCloud(data.text)\n",
    "        \n",
    "    def countAnalysis(self, data):\n",
    "        \"\"\"\n",
    "        데이터 수량 조사\n",
    "        \n",
    "        - input\n",
    "        : data / DataFrame / documents.csv 데이터\n",
    "        \"\"\"\n",
    "        \n",
    "        labeled_data = data.loc[data.label != -1]\n",
    "        total_count = len(data) # 전체 데이터 수\n",
    "        labeled_count = len(labeled_data) # 라벨링 된 데이터 수\n",
    "\n",
    "        print('> 데이터 수량 조사')\n",
    "        print(f'전체 데이터 수: {total_count}개')\n",
    "        print(f'라벨링된 데이터 수: {labeled_count}개')\n",
    "        for label, count in data.label.value_counts().iteritems():\n",
    "            print(f'class {label} : {count}개')\n",
    "    \n",
    "    def textAnalysis(self, data):\n",
    "        \"\"\"\n",
    "        text 길이 분석\n",
    "        \n",
    "        - input\n",
    "        : data / DataFrame / documents.csv 데이터\n",
    "        \"\"\"\n",
    "        text_len = data.text.apply(len)\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.hist(text_len, bins=200, alpha=0.5, color= 'r', label='length of text')\n",
    "        plt.legend(fontsize='x-large')\n",
    "        plt.yscale('log', nonposy='clip')\n",
    "        plt.title('Log-Histogram of length of text')\n",
    "        plt.xlabel('Length of text')\n",
    "        plt.ylabel('Number of text')\n",
    "\n",
    "        print('> 문장 길이 분석')\n",
    "        print('문장 길이 최대 값: {}'.format(np.max(text_len)))\n",
    "        print('문장 길이 최소 값: {}'.format(np.min(text_len)))\n",
    "        print('문장 길이 평균 값: {:.2f}'.format(np.mean(text_len)))\n",
    "        print('문장 길이 표준편차: {:.2f}'.format(np.std(text_len)))\n",
    "        print('문장 길이 중간 값: {}'.format(np.median(text_len)))\n",
    "\n",
    "        # 사분위의 대한 경우는 0~100 스케일로 되어있음\n",
    "        print('문장 길이 제 1 사분위: {}'.format(np.percentile(text_len, 25)))\n",
    "        print('문장 길이 제 3 사분위: {}'.format(np.percentile(text_len, 75)))\n",
    "            \n",
    "    def showWordCloud(self, text):\n",
    "        \"\"\"\n",
    "        WordCloud\n",
    "        \n",
    "        - input\n",
    "        : text / str / data['text'] (벡터화 하는데 사용되는 문자열)\n",
    "        \"\"\"\n",
    "        # 한글 폰트 깨짐방지\n",
    "        for font in [\"/Library/Fonts/NanumGothic.ttf\", \"/Library/Fonts/NotoSansCJKkr-Light.otf\"]:\n",
    "            if os.path.isfile(font):\n",
    "                FONT_PATH = font\n",
    "                break\n",
    "        cloud = WordCloud(font_path=FONT_PATH).generate(\" \".join(text))\n",
    "        plt.figure(figsize=(20, 15))\n",
    "        plt.imshow(cloud)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## document.py\n",
    "- [awesome-devblog : feeds](https://awesome-devblog.now.sh/api/korean/people/feeds)\n",
    "- [nero google drive: labeled data](https://drive.google.com/drive/u/0/folders/1Npfrh6XmeABJ8JJ6ApS1T88vVoqyDH7M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./document.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile ./document.py\n",
    "import os, re, csv, requests, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "from tqdm import trange\n",
    "from bs4 import BeautifulSoup\n",
    "from util import downloadByURL\n",
    "\n",
    "class KEYS(Enum):\n",
    "    # -1 : 아직 라벨링 안함 (default)\n",
    "    # 0  : 개발과 관련없는 문서\n",
    "    # 1  : 개발과 관련있는 문서\n",
    "    LABEL = 'label'\n",
    "    \n",
    "    # TAGS + TITLE + DESC\n",
    "    TEXT = 'text'\n",
    "    \n",
    "    # DATA_URL 결과 파싱용 Keys(Beans)\n",
    "    ID = '_id'\n",
    "    TITLE = 'title'\n",
    "    DESC = 'description'\n",
    "    TAGS = 'tags'\n",
    "    LINK = 'link'\n",
    "    \n",
    "    def getDocKeys():\n",
    "        \"\"\"\n",
    "        awesome-devblog API 요청시 가져오려는 컬럼\n",
    "        \n",
    "        - return\n",
    "        : list / 컬럼명 리스트\n",
    "        \"\"\"\n",
    "        return [KEYS.ID.value, KEYS.TITLE.value, KEYS.DESC.value, KEYS.TAGS.value, KEYS.LINK.value]\n",
    "    \n",
    "    def getTitleBlackList():\n",
    "        \"\"\"\n",
    "        title 컬럼 기준 블랙리스트\n",
    "        \n",
    "        - return\n",
    "        : list / 블랙리스트\n",
    "        \"\"\"\n",
    "        return ['', 'about']\n",
    "    \n",
    "    def getTextKeys():\n",
    "        \"\"\"\n",
    "        text 컬럼에 사용되는 awesome-devblog 컬럼\n",
    "        \n",
    "        - return\n",
    "        : list / 컬럼명 리스트\n",
    "        \"\"\"\n",
    "        return [KEYS.TAGS.value, KEYS.TITLE.value, KEYS.DESC.value]\n",
    "\n",
    "class Document():\n",
    "    \n",
    "    def __init__(self, update=False):\n",
    "        \n",
    "        # Constant\n",
    "        self.DATA_URL = 'https://awesome-devblog.now.sh/api/korean/people/feeds'\n",
    "        self.DOCUMENTS_PATH = './data/documents.csv'\n",
    "        self.DOCUMENTS_URL = 'https://drive.google.com/uc?id=1K5Isidyb1O7OXQ47Yk2fMVYBvEoL6W4-&export=download'\n",
    "        self.MAX_REQ_SIZE = 5000\n",
    "        \n",
    "        # 기본 폴더 생성\n",
    "        for path in ['./data', './model', './wv_model']:\n",
    "            if not os.path.isdir(path):\n",
    "                os.makedirs(path)\n",
    "                \n",
    "        # ./data/documents.csv가 없는 경우 Google Driver에서 받아옴\n",
    "        # 자동 다운로드가 안될 경우 아래 경로에서 직접 받아 ./data 폴더 하위에 추가하면 됨\n",
    "        # https://drive.google.com/drive/u/0/folders/1Npfrh6XmeABJ8JJ6ApS1T88vVoqyDH7M\n",
    "        if not os.path.isfile(self.DOCUMENTS_PATH):\n",
    "            print('라벨링된 데이터를 다운로드합니다.')\n",
    "            downloadByURL(self.DOCUMENTS_URL, self.DOCUMENTS_PATH)\n",
    "        \n",
    "        if update:\n",
    "            self.updateDocs()\n",
    "        \n",
    "    def _getTotal(self):\n",
    "        \"\"\"\n",
    "        awesome-devblog에 전체 문서 개수 요청\n",
    "        \n",
    "        - return\n",
    "        : int / 전체 문서 개수\n",
    "        \"\"\"\n",
    "        res = requests.get(self.DATA_URL, { 'size': 1 })\n",
    "        res.raise_for_status()\n",
    "        doc = res.json()\n",
    "        return doc['total'][0]['count']\n",
    "\n",
    "    def _reqDoc(self, page, size, preprocessing=False):\n",
    "        \"\"\"\n",
    "        awesome-devblog에 문서 요청\n",
    "        : KEYS에 지정된 컬럼만 가져옴\n",
    "        \n",
    "        - input\n",
    "        : page / int / 요청 페이지(0부터 시작)\n",
    "        : size / int / 한 번의 요청으로 가져오려는 문서 개수\n",
    "        : preprocessing / boolean / 문서 전처리 여부\n",
    "        \n",
    "        - output\n",
    "        : DataFrame / DataFrame(response['data'])\n",
    "        \"\"\"\n",
    "        page += 1\n",
    "        params = {\n",
    "            'sort': 'date.asc',\n",
    "            'page': page,\n",
    "            'size': size\n",
    "        }\n",
    "        res = requests.get(self.DATA_URL, params)\n",
    "        res.raise_for_status()\n",
    "        doc = res.json()\n",
    "        \n",
    "        # json to dataframe\n",
    "        doc = pd.DataFrame(doc['data'], columns=KEYS.getDocKeys())\n",
    "        \n",
    "        # add label\n",
    "        doc.insert(0, KEYS.LABEL.value, -1)\n",
    "        \n",
    "        if preprocessing:\n",
    "            return self.preprocessing(doc)\n",
    "        else:\n",
    "            return doc\n",
    "\n",
    "    def _reqDocs(self, size, start_page=0):\n",
    "        \"\"\"\n",
    "        awesome-devblog에 전체 문서 요청\n",
    "        - input\n",
    "        : size / int / 한 번의 요청으로 가져올 문서개수(max 5000)\n",
    "        : start_page / int / 해당 페이지 부터 마지막 페이지까지 조회\n",
    "        \n",
    "        - return\n",
    "        : DataFrame / 전처리된 전체 데이터로 구성\n",
    "        \"\"\"\n",
    "        total = self._getTotal()\n",
    "        if size > self.MAX_REQ_SIZE: size = self.MAX_REQ_SIZE\n",
    "        total_req = round(total/size + 0.5)\n",
    "        docs = pd.DataFrame()\n",
    "        for i in trange(start_page, total_req):\n",
    "            doc = self._reqDoc(i, size)\n",
    "            if docs.empty:\n",
    "                docs = doc\n",
    "            else:\n",
    "                docs = docs.append(doc)\n",
    "        return self.preprocessing(docs)\n",
    "    \n",
    "    def preprocessing(self, doc, joinTags=True):\n",
    "        \"\"\"\n",
    "        문서 전처리\n",
    "        : tags / 배열로 되어있으므로 띄어쓰기로 join\n",
    "        : title, description, tags / 영어, 한글, 공백만 남김\n",
    "        : html tag 삭제\n",
    "        : \\n, \\r 삭제\n",
    "        : 2회 이상의 공백은 하나로 줄입\n",
    "        : 영어 대문자 소문자로 변환\n",
    "        : 앞뒤 공백 삭제\n",
    "        : 블랙리스트 데이터(KEYS.getTitleBlackList()) 제외\n",
    "        : text / tags + title + description 순서로 join된 컬럼 생성\n",
    "        \n",
    "        - input\n",
    "        : doc / DataFrame / documents.csv DataFrame\n",
    "        : joinTags / boolean / tags join 여부\n",
    "        \n",
    "        - return\n",
    "        : DataFrame / 전처리 완료된 데이터\n",
    "        \"\"\"\n",
    "        \n",
    "        # title, description, tags\n",
    "        def textPreprocessing(x):\n",
    "            x = BeautifulSoup(str(x), \"html.parser\").get_text()\n",
    "            x = re.sub('[^가-힣a-zA-Z\\s]', '', x)\n",
    "            return x\n",
    "        \n",
    "        # all\n",
    "        def docPreprocessing(x):\n",
    "            x = re.sub('[\\n\\r]', '', x)\n",
    "            x = re.sub('\\s{2,}', ' ', x)\n",
    "            x = x.lower()\n",
    "            x = x.strip()\n",
    "            return x\n",
    "        \n",
    "        for key in doc.columns:\n",
    "            if joinTags and KEYS(key) == KEYS.TAGS:\n",
    "                doc[key] = doc[key].apply(lambda x: ' '.join(x))\n",
    "            if key in KEYS.getTextKeys():\n",
    "                doc[key] = doc[key].apply(textPreprocessing)\n",
    "                \n",
    "            if key in KEYS.getDocKeys():\n",
    "                doc[key] = doc[key].apply(docPreprocessing)\n",
    "            \n",
    "        # remove blacklist\n",
    "        doc = doc.drop(doc[doc[KEYS.TITLE.value].isin(KEYS.getTitleBlackList())].index).reset_index()\n",
    "                        \n",
    "        # create text column\n",
    "        join_with = lambda x: ' '.join(x.dropna().astype(str)).strip()\n",
    "        doc[KEYS.TEXT.value] = doc[KEYS.getTextKeys()].apply(\n",
    "            join_with,\n",
    "            axis=1\n",
    "        )\n",
    "        return doc\n",
    "    \n",
    "    def getDocs(self, labeled_only=True):\n",
    "        \"\"\"\n",
    "        전체 문서 조회\n",
    "        - input\n",
    "        : labeled_only / boolean / 라벨링 된 데이터만 가져올지 선택\n",
    "        \n",
    "        - return\n",
    "        : DataFrame / documents.csv 데이터\n",
    "        \"\"\"\n",
    "        if not os.path.isfile(self.DOCUMENTS_PATH):\n",
    "            print('> 문서가 없으므로 서버에 요청합니다.')\n",
    "            self.updateDocs()\n",
    "        data = pd.read_csv(self.DOCUMENTS_PATH, delimiter=',', dtype={KEYS.LABEL.value: np.int64})\n",
    "        if not labeled_only:\n",
    "            return data\n",
    "        else:\n",
    "            return data.loc[data.label != -1]\n",
    "    \n",
    "    def updateDocs(self):\n",
    "        \"\"\"\n",
    "        awesome-devblog에 최신 문서 요청 및 documents.csv에 추가\n",
    "        : 데이터가 없는 경우, 전체 데이터를 가져옴\n",
    "        : 기존 데이터가 있는 경우, 없는 데이터만 추가\n",
    "       \n",
    "        - export\n",
    "        : ./data/documents.csv가 없는 경우 신규 생성\n",
    "        : ./data/documents.csv가 있는 경우 신규 문서 추가\n",
    "        \"\"\"\n",
    "        size = self.MAX_REQ_SIZE\n",
    "        \n",
    "        if not os.path.isfile(self.DOCUMENTS_PATH):\n",
    "            # 데이터가 없는 경우\n",
    "            docs = self._reqDocs(size)\n",
    "            docs.to_csv(self.DOCUMENTS_PATH, sep=\",\", index=False)\n",
    "        else:\n",
    "            # 기존 데이터가 있는 경우\n",
    "            num_new_docs = 0\n",
    "            docs = pd.read_csv(self.DOCUMENTS_PATH, delimiter=',')\n",
    "            total = self._getTotal()\n",
    "            total_docs = len(docs)\n",
    "            new_docs_num = total - total_docs\n",
    "            new_docs = self._reqDocs(size, total_docs // size)\n",
    "            \n",
    "            # _id가 기존 데이터에 존재하지 않는 경우에만 추가\n",
    "            docs = docs.append(new_docs[~new_docs[KEYS.ID.value].isin(docs[KEYS.ID.value])])\n",
    "            docs.to_csv(self.DOCUMENTS_PATH, sep=\",\", index=False)\n",
    "            \n",
    "            if total_docs == len(docs):\n",
    "                print('> 문서가 최신 상태입니다.')\n",
    "            else:\n",
    "                print(f'> 신규 문서 {len(docs) - total_docs}개 추가')\n",
    "    \n",
    "    def syncDocLabel(self, old_document_path, sep, override=False):\n",
    "        \"\"\"\n",
    "        기존 라벨링한 데이터를 신규 문서에 반영\n",
    "        : title, link 기준으로 일치하는 문서 검색\n",
    "        \n",
    "        - input\n",
    "        : old_document_path / str / 기존 라벨링한 데이터 경로\n",
    "        : sep / str / csv delimiter\n",
    "        : override / boolean / 기존 라벨링이 반영된 결과를 ./data/documents.csv로 저장여부\n",
    "        \n",
    "        - export\n",
    "        : ./data/documents.csv\n",
    "        \"\"\"\n",
    "        \n",
    "        document = pd.read_csv(self.DOCUMENTS_PATH, delimiter=',')\n",
    "        old_document = pd.read_csv(old_document_path, delimiter=sep)\n",
    "        self.preprocessing(old_document, joinTags=False)\n",
    "        for index, row in old_document.iterrows():\n",
    "            link = row.link\n",
    "            title = row.title\n",
    "            label = int(row.label)\n",
    "            if not len(document.loc[document.title.str.strip() == title.strip()]) and not len(document.loc[document.link == link]):\n",
    "                print(f'not found : {row.title}')\n",
    "            elif len(document.loc[document.title.str.strip() == title.strip()]):\n",
    "                document.loc[document.title.str.strip() == title.strip(), KEYS.LABEL.value] = label\n",
    "            elif len(document.loc[document.link == link]):\n",
    "                document.loc[document.link == link, KEYS.LABEL.value] = label\n",
    "        \n",
    "        # save synchronized document\n",
    "        if override:\n",
    "            document.to_csv(self.DOCUMENTS_PATH, sep=\",\", index=False)\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word_vector.py\n",
    "- [FastText wiki 한국어 데이터](https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ko.300.bin.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./word_vector.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile ./word_vector.py\n",
    "import os\n",
    "import numpy as np\n",
    "from util import downloadByURL\n",
    "from gensim.models import FastText, fasttext # 둘이 다름 주의!\n",
    "\n",
    "\"\"\"\n",
    "FastText base word embedding\n",
    "\"\"\"\n",
    "class WordVector():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # corpus\n",
    "        self.WIKI_KO_DATA = './data/cc.ko.300.bin.gz'\n",
    "        self.WIKI_KO_DATA_URL = 'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ko.300.bin.gz'\n",
    "\n",
    "        # pretrained model\n",
    "        self.WIKI_KO_MODEL_PATH = f'./wv_model/ko.wiki'\n",
    "\n",
    "    def getCustomModel(self, sentences, embedding_dim=4, window=3, min_count=1, epochs=10):\n",
    "        \"\"\"\n",
    "        주어진 문장들을 기반으로 FastText 단어 임베딩 모델 학습\n",
    "        \n",
    "        - input\n",
    "        : sentences / list / 학습에 사용될 문장 배열\n",
    "        : embedding_dim / int / 단어 벡터화시 차원 수\n",
    "        : window / int / 학습에 사용될 n-gram\n",
    "        : min_count / int / 학습에 사용될 단어의 최소 등장횟수\n",
    "        : epochs / int / 학습 횟수\n",
    "        \n",
    "        - return\n",
    "        : wv_model\n",
    "        \"\"\"\n",
    "        model = FastText(size=embedding_dim, window=window, min_count=min_count)\n",
    "        model.build_vocab(sentences=sentences)\n",
    "        model.train(sentences=sentences, total_examples=len(sentences), epochs=epochs)\n",
    "        return model\n",
    "    \n",
    "    def getWikiModel(self):\n",
    "        \"\"\"\n",
    "        위키 한국어 데이터를 기반으로 FastText 단어 임베딩 모델 학습\n",
    "        : 기존 학습된 모델이 있는 경우 해당 모델 반환\n",
    "        : 위키 한국어 데이터(./data/cc.ko.300.bin.gz)가 없는 경우 다운로드\n",
    "        : 기존 학습된 모델이 없는 경우 학습\n",
    "        : 학습된 결과를 ./wv_model에 저장\n",
    "        \n",
    "        - export\n",
    "        : self.WIKI_KO_MODEL_PATH\n",
    "        \"\"\"\n",
    "        model = None\n",
    "        if not os.path.isfile(self.WIKI_KO_MODEL_PATH):\n",
    "            print('학습된 단어 임베딩 모델이 없습니다.')\n",
    "            \n",
    "            if not os.path.isfile(self.WIKI_KO_DATA):\n",
    "                print('단어 임베딩 모델 학습에 필요한 데이터를 다운로드를 시작합니다.')\n",
    "                downloadByURL(self.WIKI_KO_DATA_URL, self.WIKI_KO_DATA)\n",
    "            \n",
    "            print('단어 임베딩 모델 학습을 시작합니다.')\n",
    "            model = fasttext.load_facebook_model(self.WIKI_KO_DATA)\n",
    "            \n",
    "            print('단어 임베딩 모델을 저장합니다.')\n",
    "            model.save(self.WIKI_KO_MODEL_PATH)\n",
    "        else:\n",
    "            model = FastText.load(self.WIKI_KO_MODEL_PATH)\n",
    "        \n",
    "        # print(f'vocab size : {len(model.wv.vocab)}') # 2,000,000\n",
    "        return model\n",
    "    \n",
    "    def getSimilarWords(self, wv_model, word, topn=5):\n",
    "        \"\"\"\n",
    "        유사단어 조회\n",
    "        \n",
    "        - input\n",
    "        : wv_model / FastText 단어 임베딩 모델\n",
    "        : word / str / 유사도를 측정하려는 단어\n",
    "        : topn / int / 조회 개수\n",
    "        \"\"\"\n",
    "        return wv_model.wv.similar_by_word(word, topn)\n",
    "    \n",
    "    def vectorization(self, wv_model, text, embedding_dim=300):\n",
    "        \"\"\"\n",
    "        주어진 문장을 단어별로 벡터화한 뒤 평균값을 문장의 벡터로 반환\n",
    "        \n",
    "        - input\n",
    "        : wv_model / FastText 단어 임베딩 모델\n",
    "        : text / str / 벡터화하려는 문장\n",
    "        : embedding_dim / int / wv_model vector의 차원 수 (wiki 기반 fasttext는 300차원)\n",
    "        \n",
    "        - return\n",
    "        : nparray / shape = (embedding_dim)\n",
    "        \"\"\"\n",
    "        words = text.split(' ')\n",
    "        words_num = len(words)\n",
    "        \n",
    "        # model dimension (wiki festtext의 경우 300)\n",
    "        vector = np.zeros(embedding_dim)\n",
    "        for word in words:\n",
    "            vector += wv_model[word]\n",
    "        return vector/words_num\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./classifier.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile ./classifier.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "class Classifier():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.history = None\n",
    "        \n",
    "    def _reshape(self, x):\n",
    "        \"\"\"\n",
    "        LSTM 계열의 레이어 사용시 필요한 (total, embedding_dim, 1) 형태의 shape로 변환\n",
    "        \n",
    "        - input\n",
    "        : x / nparray / 변환하려는 배열\n",
    "        \n",
    "        - return\n",
    "        : nparray\n",
    "        \"\"\"\n",
    "        return x.reshape(x.shape[0], x.shape[1], 1)\n",
    "    \n",
    "    def _dataSeperator(self, data, test_size=0.33):\n",
    "        \"\"\"\n",
    "        데이터 분할\n",
    "        \n",
    "        - input\n",
    "        : data / DataFrame / documents.csv 데이터\n",
    "        : test_size / float / 데이터 분할 비율\n",
    "        \n",
    "        - return\n",
    "        : [nparray, nparray, nparray, nparray]\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data.vector,\n",
    "                                                            data.label,\n",
    "                                                            test_size=test_size,\n",
    "                                                            random_state=321)\n",
    "        X_train = np.array(X_train.tolist(), dtype=np.float32)\n",
    "        X_test = np.array(X_test.tolist(), dtype=np.float32)\n",
    "        y_train = np.array(y_train.tolist(), dtype=np.int32)\n",
    "        y_test = np.array(y_test.tolist(), dtype=np.int32)\n",
    "        return X_train, X_test, np.asarray(y_train), np.asarray(y_test)\n",
    "        \n",
    "    def train(self,\n",
    "              data,\n",
    "              checkpoint_path,\n",
    "              epochs=75,\n",
    "              batch_size=100,\n",
    "              validation_split=0.1,\n",
    "              verbose=0):\n",
    "        \"\"\"\n",
    "        모델 학습\n",
    "    \n",
    "        - input\n",
    "        : data / DataFrame / documents.csv 데이터\n",
    "        : checkpoint_path / str / 학습 중간 결과물 저장 경로\n",
    "        : epochs / int / 학습 횟수\n",
    "        : batch_size / int / 배치 사이즈\n",
    "        : validation_split / float / validation data ratio\n",
    "        : verbose / int / 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "\n",
    "        - return\n",
    "        : classifier\n",
    "        \n",
    "        - export\n",
    "        : ./model/classifier.json (graph)\n",
    "        : ./model/classifier.h5 (weights)\n",
    "        \"\"\"\n",
    "        \n",
    "        # seperate data\n",
    "        X_train, X_test, y_train, y_test = self._dataSeperator(data)\n",
    "        \n",
    "        # model\n",
    "        K.clear_session()\n",
    "        model = Sequential()\n",
    "        model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(X_train.shape[1],)))\n",
    "        model.add(Dense(80, activation='relu', kernel_initializer='he_normal'))\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['acc',\n",
    "                               self.f1_m,\n",
    "                               self.precision_m,\n",
    "                               self.recall_m])\n",
    "        model.summary()\n",
    "        \n",
    "        # checkpoint\n",
    "        checkpoint = ModelCheckpoint(filepath=checkpoint_path, mode='max', monitor='val_acc', verbose=2, save_best_only=True)\n",
    "        callbacks_list = [checkpoint]\n",
    "        \n",
    "        # early stopping\n",
    "        earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=1)\n",
    "        \n",
    "        self.history = model.fit(X_train,\n",
    "                            y_train,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            validation_split=validation_split,\n",
    "                            callbacks=callbacks_list)\n",
    "        loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=verbose)\n",
    "        print(f'loss : {loss}')\n",
    "        print(f'accuracy : {accuracy}')\n",
    "        print(f'f1_score : {f1_score}')\n",
    "        print(f'precision : {precision}')\n",
    "        print(f'recall : {recall}')\n",
    "        return model\n",
    "        \n",
    "    def saveModel(self, model, path):\n",
    "        \"\"\"\n",
    "        모델의 parameter와 weights를 저장한다.\n",
    "        \n",
    "        - input\n",
    "        : model / classifier\n",
    "        : path / export 경로 ex)./model/classifier\n",
    "        \n",
    "        - export\n",
    "        : ./model/classifier.json / parameter\n",
    "        : ./model/classifier.h5 / weights\n",
    "        \"\"\"\n",
    "        # save model\n",
    "        model_json = model.to_json()\n",
    "        with open(path + '.json', \"w\") as json_file : \n",
    "            json_file.write(model_json)\n",
    "        \n",
    "        # save weights\n",
    "        model.save_weights(path + '.h5')\n",
    "        \n",
    "    def loadModel(self, path):\n",
    "        \"\"\"\n",
    "        모델을 불러옴\n",
    "        \n",
    "        - return\n",
    "        : classifier\n",
    "        \"\"\"\n",
    "        # load model\n",
    "        with open(path + '.json', \"r\") as json_file:\n",
    "            json_model = json_file.read()\n",
    "        model = model_from_json(json_model)\n",
    "        \n",
    "        # load weight\n",
    "        model.load_weights(path + '.h5')\n",
    "        return model\n",
    "        \n",
    "    def showHistory(self):\n",
    "        \"\"\"\n",
    "        train history를 그래프로 나타냄\n",
    "        \"\"\"\n",
    "        if self.history == None:\n",
    "            print('학습내역이 없습니다.')\n",
    "            return\n",
    "        \n",
    "        fig, loss_ax = plt.subplots()\n",
    "        acc_ax = loss_ax.twinx()\n",
    "        acc_ax.plot(self.history.history['acc'], 'b', label='train acc')\n",
    "        acc_ax.plot(self.history.history['val_acc'], 'g', label='val acc')\n",
    "        acc_ax.set_ylabel('accuracy')\n",
    "        acc_ax.legend(loc='upper left')\n",
    "        plt.show()\n",
    "    \n",
    "    def recall_m(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        재현율(실제 True인 것 중에서 모델이 True라고 예측한 것의 비율) 계산\n",
    "        \n",
    "        - input\n",
    "        : y_true / int / 정답\n",
    "        : y_pred / int / 모델 예측결과\n",
    "        \n",
    "        - return\n",
    "        : float\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision_m(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        정밀도(모델이 True라고 분류한 것 중에서 실제 True인 것의 비율) 계산\n",
    "        \n",
    "        - input\n",
    "        : y_true / int / 정답\n",
    "        : y_pred / int / 모델 예측결과\n",
    "        \n",
    "        - return\n",
    "        : float\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    def f1_m(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        F1 score(Precision과 Recall의 조화평균) 계산\n",
    "        \n",
    "        - input\n",
    "        : y_true / int / 정답\n",
    "        : y_pred / int / 모델 예측결과\n",
    "        \n",
    "        - return\n",
    "        : float\n",
    "        \"\"\"\n",
    "        precision = self.precision_m(y_true, y_pred)\n",
    "        recall = self.recall_m(y_true, y_pred)\n",
    "        return 2 * ((precision * recall)/(precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['materials',\n",
       " 'ㅈㅣㄱㅈㅓㅂ',\n",
       " 'ㅈㅔ_ㅈㅏㄱㅎㅏㄴ',\n",
       " 'ㅈㅏ_ㄹㅛ_ㄹㅡㄹ',\n",
       " 'ㄱㅗㅇㅇㅠ_ㅎㅏㅂㄴㅣ_ㄷㅏ_',\n",
       " 'ㅂㅜ_ㅈㅗㄱㅎㅏㄴ',\n",
       " 'ㅂㅜ_ㅂㅜㄴㄷㅗ_',\n",
       " 'ㅁㅏㄶㄱㅗ_',\n",
       " 'ㅈㅏㄹㅁㅗㅅㄷㅚㄴ',\n",
       " 'ㅂㅜ_ㅂㅜㄴㅇㅣ_',\n",
       " 'ㅇㅣㅆㅇㅡㄹ',\n",
       " 'ㅅㅜ_ㄷㅗ_',\n",
       " 'ㅇㅣㅆㅅㅡㅂㄴㅣ_ㄷㅏ_',\n",
       " 'ㅇㅓㄴㅈㅔ_ㄷㅡㄴㅈㅣ_',\n",
       " 'ㅈㅣ_ㅈㅓㄱㅎㅐ_ㅈㅜ_ㅅㅣ_ㅁㅕㄴ',\n",
       " 'ㅊㅏㅁㄱㅗ_ㅎㅏ_ㄷㅗ_ㄹㅗㄱ',\n",
       " 'ㅎㅏ_ㄱㅔㅆㅅㅡㅂㄴㅣ_ㄷㅏ_',\n",
       " 'ㄱㅏㅁㅅㅏ_ㅎㅏㅂㄴㅣ_ㄷㅏ_',\n",
       " 'ㄷㅔ_ㅇㅣ_ㅌㅓ_',\n",
       " 'ㅂㅜㄴㅅㅓㄱ']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'materials 직접 제작한 자료를 공유합니다 부족한 부분도 많고 잘못된 부분이 있을 수도 있습니다 언제든지 지적해주시면 참고하도록 하겠습니다 감사합니다 데이터 분석'\n",
    "\n",
    "[han2Jamo(s) for s in text.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = Document()\n",
    "wv = WordVector()\n",
    "cf = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docs = dc.getDocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = dc.getDocs(labeled_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'materials 직접 제작한 자료를 공유합니다 부족한 부분도 많고 잘못된 부분이 있을 수도 있습니다 언제든지 지적해주시면 참고하도록 하겠습니다 감사합니다 데이터 분석'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs.text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = all_docs.text.apply(lambda x: [han2Jamo(s) for s in x.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                  [fixed]\n",
       "1        [materials, ㅈㅣㄱㅈㅓㅂ, ㅈㅔ_ㅈㅏㄱㅎㅏㄴ, ㅈㅏ_ㄹㅛ_ㄹㅡㄹ, ㄱㅗㅇㅇ...\n",
       "2        [support, ㅂㅡㄹㄹㅗ_ㄱㅡ_ㄱㅏ_, ㄷㅗ_ㅇㅜㅁㅇㅣ_, ㄷㅚ_ㅅㅕㅆㄴㅏ_ㅇㅛ...\n",
       "3        [materials, ㅈㅣㄱㅈㅓㅂ, ㅈㅔ_ㅈㅏㄱㅎㅏㄴ, ㅈㅏ_ㄹㅛ_ㄹㅡㄹ, ㄱㅗㅇㅇ...\n",
       "4                                       [hugo, test, page]\n",
       "                               ...                        \n",
       "34615    [javascript, algorithm, algorithmleetcode, bin...\n",
       "34616    [likely, and, unlikely, ㄱㅐ_ㅇㅛ_, ㅇㅖ_ㅈㅓㄴㅇㅔ_, ㄱㅘㄴ...\n",
       "34617    [spring, boot, jpa, spring, spring, boot, spri...\n",
       "34618    [android, ㅈㅜ_, ㅍㅡ_ㄹㅗ_ㅈㅔㄱㅌㅡ_, dev, log, ㅇㅣ_ㅁㅣ_ㅈ...\n",
       "34619    [ㅇㅓㅂㅁㅜ_, ㅅㅣ_ㄱㅏㄱㅎㅘ_, ㅊㅜ_ㅊㅓㄴ, ㅇㅕ_ㅂㅜ_, ㅊㅜ_ㅊㅓㄴ, ㅊㅜ...\n",
       "Name: text, Length: 34620, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-e58a27759efc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwv_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCustomModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-fc61ca7d1140>\u001b[0m in \u001b[0;36mgetCustomModel\u001b[0;34m(self, sentences, embedding_dim, window, min_count, epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/devbog_classifier/lib/python3.7/site-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    923\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/devbog_classifier/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/devbog_classifier/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[1;32m    552\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[1;32m    554\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001b[0;32m~/.virtualenvs/devbog_classifier/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[1;32m    487\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m    488\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/devbog_classifier/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wv_model = wv.getCustomModel(text, embedding_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅍㅏ_ㅇㅣ_ㅆㅓㄴㅇㅔㄴ', 0.9904079437255859),\n",
       " ('sortㅍㅏ_ㅇㅣ_ㅆㅓㄴ', 0.9853756427764893),\n",
       " ('ㅍㅏ_ㅇㅣ_ㅆㅓㄴㅇㅛㅇ', 0.9806692004203796),\n",
       " ('randomㅍㅏ_ㅇㅣ_ㅆㅓㄴ', 0.977226972579956),\n",
       " ('ㅍㅏ_ㅇㅣ_ㅆㅓㄴㅁㅏㄴ', 0.9724537134170532),\n",
       " ('indexㅍㅏ_ㅇㅣ_ㅆㅓㄴ', 0.9710382223129272),\n",
       " ('ㅍㅏ_ㅇㅣ_ㅆㅓㄴㅊㅓ_ㄹㅓㅁ', 0.9682952165603638),\n",
       " ('ㅍㅏ_ㅇㅣ_ㅆㅓㄴㅇㅣㄹ', 0.9679751396179199),\n",
       " ('pythonㅍㅏ_ㅇㅣ_ㅆㅓㄴ', 0.9637205600738525),\n",
       " ('ㅈㅓㅁㅍㅡ_ㅌㅜ_ㅍㅏ_ㅇㅣ_ㅆㅓㄴ', 0.9608114957809448)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_model.wv.similar_by_word(han2Jamo('파이썬'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>5dacbde600c37100040ba7c4</td>\n",
       "      <td>about me</td>\n",
       "      <td>뭐하세요 전남대학교 전자컴퓨터공학부 재학 뭐했어요 전남대학교 동아리 정보보호 준회원...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://koyo.kr/page/about/</td>\n",
       "      <td>about me 뭐하세요 전남대학교 전자컴퓨터공학부 재학 뭐했어요 전남대학교 동아리...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>386</td>\n",
       "      <td>413</td>\n",
       "      <td>0</td>\n",
       "      <td>5e0410563e8fe0000414586d</td>\n",
       "      <td>근황</td>\n",
       "      <td>제 블로그에 들어와본지도 오래됐네요 북마크를 잘못 눌러서 제 블로그에 들어왔다가 방...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://blog.hatemogi.com/143</td>\n",
       "      <td>근황 제 블로그에 들어와본지도 오래됐네요 북마크를 잘못 눌러서 제 블로그에 들어왔다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>554</td>\n",
       "      <td>591</td>\n",
       "      <td>0</td>\n",
       "      <td>5e045c11e3e06b0004ce092e</td>\n",
       "      <td>년 월 일</td>\n",
       "      <td>년이 시작한 지도 벌써 이틀이 지나 월 일 다른 블로그에서 년을 마무리하는 글들이 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://bomjun.tistory.com/11</td>\n",
       "      <td>년 월 일 년이 시작한 지도 벌써 이틀이 지나 월 일 다른 블로그에서 년을 마무리하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>644</td>\n",
       "      <td>684</td>\n",
       "      <td>0</td>\n",
       "      <td>5cd65b556d45ff0004343926</td>\n",
       "      <td>hello world</td>\n",
       "      <td>hello world this is the beginning of this theme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://000namc.github.io/blog/2013/04/22/hell...</td>\n",
       "      <td>hello world hello world this is the beginning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>760</td>\n",
       "      <td>810</td>\n",
       "      <td>0</td>\n",
       "      <td>5c658301e0753928c2de3bc9</td>\n",
       "      <td>근황</td>\n",
       "      <td>dfest 장려상 deview 첫날 bof 시간에 croquisjs 발표자로 참가하...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://blog.0xabcdef.com/100197681277</td>\n",
       "      <td>근황 dfest 장려상 deview 첫날 bof 시간에 croquisjs 발표자로 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34516</th>\n",
       "      <td>34516</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5dcaa0cc9251e50004927a1b</td>\n",
       "      <td>unityd tilemap 룰 타일로 타일맵 자동 연결하기</td>\n",
       "      <td>tilemap 룰 타일로 타일맵 자동 연결하기작성 기준 버전 f지난 섹션에서는 간단...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wergia.tistory.com/200</td>\n",
       "      <td>unityd tilemap 룰 타일로 타일맵 자동 연결하기 tilemap 룰 타일로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34517</th>\n",
       "      <td>34517</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5dca9fd99251e50004927a19</td>\n",
       "      <td>애자일과 소프트웨어 장인정신 코드 리뷰를 왜 해야 하나</td>\n",
       "      <td>가끔 애자일을 구성원들에게 교육하고 애자일 코치를 통해 애자일 기법이나 절차스크럼 ...</td>\n",
       "      <td>code review</td>\n",
       "      <td>https://brunch.co.kr/@@2xm/39</td>\n",
       "      <td>code review 애자일과 소프트웨어 장인정신 코드 리뷰를 왜 해야 하나 가끔 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34518</th>\n",
       "      <td>34518</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5dcaae1a36f8990004dd10fe</td>\n",
       "      <td>paper staring into the abyss an evaluation of ...</td>\n",
       "      <td>xiangyao yu george bezerra andrew pavlo sriniv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://blog.lastmind.io/archives/903</td>\n",
       "      <td>paper staring into the abyss an evaluation of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34545</th>\n",
       "      <td>34545</td>\n",
       "      <td>879</td>\n",
       "      <td>1</td>\n",
       "      <td>5de215daa6b34b00041ecb22</td>\n",
       "      <td>b급 프로그래머 월 주 소식개발관리도구 고성능 서버데이터베이스 부문</td>\n",
       "      <td>오늘의 짤방 hacking tools cheat sheet via alraees 개...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://feedproxy.google.com/~r/blogspot/aspe/~...</td>\n",
       "      <td>b급 프로그래머 월 주 소식개발관리도구 고성능 서버데이터베이스 부문 오늘의 짤방 h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34598</th>\n",
       "      <td>34598</td>\n",
       "      <td>4997</td>\n",
       "      <td>1</td>\n",
       "      <td>5e389934937bd12c10a16b9a</td>\n",
       "      <td>엔티티 매핑</td>\n",
       "      <td>들어가며 해당 글은 자바 orm 표준 프로그래밍을 정리한 글입니다 entity와 e...</td>\n",
       "      <td>java</td>\n",
       "      <td>https://kangwoojin.github.io/programing/%ec%97...</td>\n",
       "      <td>java 엔티티 매핑 들어가며 해당 글은 자바 orm 표준 프로그래밍을 정리한 글입...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10382 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  index  label                       _id  \\\n",
       "10             10     15      0  5dacbde600c37100040ba7c4   \n",
       "386           386    413      0  5e0410563e8fe0000414586d   \n",
       "554           554    591      0  5e045c11e3e06b0004ce092e   \n",
       "644           644    684      0  5cd65b556d45ff0004343926   \n",
       "760           760    810      0  5c658301e0753928c2de3bc9   \n",
       "...           ...    ...    ...                       ...   \n",
       "34516       34516      8      1  5dcaa0cc9251e50004927a1b   \n",
       "34517       34517     10      1  5dca9fd99251e50004927a19   \n",
       "34518       34518     14      0  5dcaae1a36f8990004dd10fe   \n",
       "34545       34545    879      1  5de215daa6b34b00041ecb22   \n",
       "34598       34598   4997      1  5e389934937bd12c10a16b9a   \n",
       "\n",
       "                                                   title  \\\n",
       "10                                              about me   \n",
       "386                                                   근황   \n",
       "554                                                년 월 일   \n",
       "644                                          hello world   \n",
       "760                                                   근황   \n",
       "...                                                  ...   \n",
       "34516                   unityd tilemap 룰 타일로 타일맵 자동 연결하기   \n",
       "34517                     애자일과 소프트웨어 장인정신 코드 리뷰를 왜 해야 하나   \n",
       "34518  paper staring into the abyss an evaluation of ...   \n",
       "34545              b급 프로그래머 월 주 소식개발관리도구 고성능 서버데이터베이스 부문   \n",
       "34598                                             엔티티 매핑   \n",
       "\n",
       "                                             description         tags  \\\n",
       "10     뭐하세요 전남대학교 전자컴퓨터공학부 재학 뭐했어요 전남대학교 동아리 정보보호 준회원...          NaN   \n",
       "386    제 블로그에 들어와본지도 오래됐네요 북마크를 잘못 눌러서 제 블로그에 들어왔다가 방...          NaN   \n",
       "554    년이 시작한 지도 벌써 이틀이 지나 월 일 다른 블로그에서 년을 마무리하는 글들이 ...          NaN   \n",
       "644      hello world this is the beginning of this theme          NaN   \n",
       "760    dfest 장려상 deview 첫날 bof 시간에 croquisjs 발표자로 참가하...          NaN   \n",
       "...                                                  ...          ...   \n",
       "34516  tilemap 룰 타일로 타일맵 자동 연결하기작성 기준 버전 f지난 섹션에서는 간단...          NaN   \n",
       "34517  가끔 애자일을 구성원들에게 교육하고 애자일 코치를 통해 애자일 기법이나 절차스크럼 ...  code review   \n",
       "34518  xiangyao yu george bezerra andrew pavlo sriniv...          NaN   \n",
       "34545  오늘의 짤방 hacking tools cheat sheet via alraees 개...          NaN   \n",
       "34598  들어가며 해당 글은 자바 orm 표준 프로그래밍을 정리한 글입니다 entity와 e...         java   \n",
       "\n",
       "                                                    link  \\\n",
       "10                           https://koyo.kr/page/about/   \n",
       "386                         http://blog.hatemogi.com/143   \n",
       "554                         http://bomjun.tistory.com/11   \n",
       "644    https://000namc.github.io/blog/2013/04/22/hell...   \n",
       "760                http://blog.0xabcdef.com/100197681277   \n",
       "...                                                  ...   \n",
       "34516                     https://wergia.tistory.com/200   \n",
       "34517                      https://brunch.co.kr/@@2xm/39   \n",
       "34518               http://blog.lastmind.io/archives/903   \n",
       "34545  http://feedproxy.google.com/~r/blogspot/aspe/~...   \n",
       "34598  https://kangwoojin.github.io/programing/%ec%97...   \n",
       "\n",
       "                                                    text  \n",
       "10     about me 뭐하세요 전남대학교 전자컴퓨터공학부 재학 뭐했어요 전남대학교 동아리...  \n",
       "386    근황 제 블로그에 들어와본지도 오래됐네요 북마크를 잘못 눌러서 제 블로그에 들어왔다...  \n",
       "554    년 월 일 년이 시작한 지도 벌써 이틀이 지나 월 일 다른 블로그에서 년을 마무리하...  \n",
       "644    hello world hello world this is the beginning ...  \n",
       "760    근황 dfest 장려상 deview 첫날 bof 시간에 croquisjs 발표자로 ...  \n",
       "...                                                  ...  \n",
       "34516  unityd tilemap 룰 타일로 타일맵 자동 연결하기 tilemap 룰 타일로...  \n",
       "34517  code review 애자일과 소프트웨어 장인정신 코드 리뷰를 왜 해야 하나 가끔 ...  \n",
       "34518  paper staring into the abyss an evaluation of ...  \n",
       "34545  b급 프로그래머 월 주 소식개발관리도구 고성능 서버데이터베이스 부문 오늘의 짤방 h...  \n",
       "34598  java 엔티티 매핑 들어가며 해당 글은 자바 orm 표준 프로그래밍을 정리한 글입...  \n",
       "\n",
       "[10382 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.text = docs.text.apply(lambda x: ' '.join([han2Jamo(s) for s in x.split(' ')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nero/.virtualenvs/devbog_classifier/lib/python3.7/site-packages/ipykernel_launcher.py:98: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "docs['vector'] = docs.text.apply(lambda x: wv.vectorization(wv_model, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>5dacbde600c37100040ba7c4</td>\n",
       "      <td>about me</td>\n",
       "      <td>뭐하세요 전남대학교 전자컴퓨터공학부 재학 뭐했어요 전남대학교 동아리 정보보호 준회원...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://koyo.kr/page/about/</td>\n",
       "      <td>about me ㅁㅝㅎㅏㅅㅔㅇㅛ ㅈㅓㄴㄴㅏㅁㄷㅐㅎㅏㄱㄱㅛ ㅈㅓㄴㅈㅏㅋㅓㅁㅍㅠㅌㅓㄱㅗ...</td>\n",
       "      <td>[-1.5842538362319048e-05, -9.35396417931077e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>386</td>\n",
       "      <td>413</td>\n",
       "      <td>0</td>\n",
       "      <td>5e0410563e8fe0000414586d</td>\n",
       "      <td>근황</td>\n",
       "      <td>제 블로그에 들어와본지도 오래됐네요 북마크를 잘못 눌러서 제 블로그에 들어왔다가 방...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://blog.hatemogi.com/143</td>\n",
       "      <td>ㄱㅡㄴㅎㅘㅇ ㅈㅔ ㅂㅡㄹㄹㅗㄱㅡㅇㅔ ㄷㅡㄹㅇㅓㅇㅘㅂㅗㄴㅈㅣㄷㅗ ㅇㅗㄹㅐㄷㅙㅆㄴㅔㅇㅛ...</td>\n",
       "      <td>[-2.0547285947197285e-05, -0.00020704209594607...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>554</td>\n",
       "      <td>591</td>\n",
       "      <td>0</td>\n",
       "      <td>5e045c11e3e06b0004ce092e</td>\n",
       "      <td>년 월 일</td>\n",
       "      <td>년이 시작한 지도 벌써 이틀이 지나 월 일 다른 블로그에서 년을 마무리하는 글들이 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://bomjun.tistory.com/11</td>\n",
       "      <td>ㄴㅕㄴ ㅇㅝㄹ ㅇㅣㄹ ㄴㅕㄴㅇㅣ ㅅㅣㅈㅏㄱㅎㅏㄴ ㅈㅣㄷㅗ ㅂㅓㄹㅆㅓ ㅇㅣㅌㅡㄹㅇㅣ ...</td>\n",
       "      <td>[0.0001649544182227045, -0.0002266320312898002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>644</td>\n",
       "      <td>684</td>\n",
       "      <td>0</td>\n",
       "      <td>5cd65b556d45ff0004343926</td>\n",
       "      <td>hello world</td>\n",
       "      <td>hello world this is the beginning of this theme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://000namc.github.io/blog/2013/04/22/hell...</td>\n",
       "      <td>hello world hello world this is the beginning ...</td>\n",
       "      <td>[-6.551726586291228e-05, 1.8461513801329684e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>760</td>\n",
       "      <td>810</td>\n",
       "      <td>0</td>\n",
       "      <td>5c658301e0753928c2de3bc9</td>\n",
       "      <td>근황</td>\n",
       "      <td>dfest 장려상 deview 첫날 bof 시간에 croquisjs 발표자로 참가하...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://blog.0xabcdef.com/100197681277</td>\n",
       "      <td>ㄱㅡㄴㅎㅘㅇ dfest ㅈㅏㅇㄹㅕㅅㅏㅇ deview ㅊㅓㅅㄴㅏㄹ bof ㅅㅣㄱㅏㄴㅇ...</td>\n",
       "      <td>[-0.00017004047499953728, 5.046020768614571e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34516</th>\n",
       "      <td>34516</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5dcaa0cc9251e50004927a1b</td>\n",
       "      <td>unityd tilemap 룰 타일로 타일맵 자동 연결하기</td>\n",
       "      <td>tilemap 룰 타일로 타일맵 자동 연결하기작성 기준 버전 f지난 섹션에서는 간단...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wergia.tistory.com/200</td>\n",
       "      <td>unityd tilemap ㄹㅜㄹ ㅌㅏㅇㅣㄹㄹㅗ ㅌㅏㅇㅣㄹㅁㅐㅂ ㅈㅏㄷㅗㅇ ㅇㅕㄴㄱ...</td>\n",
       "      <td>[4.8495559737175984e-05, -4.197198774948317e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34517</th>\n",
       "      <td>34517</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5dca9fd99251e50004927a19</td>\n",
       "      <td>애자일과 소프트웨어 장인정신 코드 리뷰를 왜 해야 하나</td>\n",
       "      <td>가끔 애자일을 구성원들에게 교육하고 애자일 코치를 통해 애자일 기법이나 절차스크럼 ...</td>\n",
       "      <td>code review</td>\n",
       "      <td>https://brunch.co.kr/@@2xm/39</td>\n",
       "      <td>code review ㅇㅐㅈㅏㅇㅣㄹㄱㅘ ㅅㅗㅍㅡㅌㅡㅇㅞㅇㅓ ㅈㅏㅇㅇㅣㄴㅈㅓㅇㅅㅣㄴ ...</td>\n",
       "      <td>[-4.8762879867519425e-05, 1.4807322986598593e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34518</th>\n",
       "      <td>34518</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5dcaae1a36f8990004dd10fe</td>\n",
       "      <td>paper staring into the abyss an evaluation of ...</td>\n",
       "      <td>xiangyao yu george bezerra andrew pavlo sriniv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://blog.lastmind.io/archives/903</td>\n",
       "      <td>paper staring into the abyss an evaluation of ...</td>\n",
       "      <td>[-2.1099355319343087e-05, -0.00011323287578040...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34545</th>\n",
       "      <td>34545</td>\n",
       "      <td>879</td>\n",
       "      <td>1</td>\n",
       "      <td>5de215daa6b34b00041ecb22</td>\n",
       "      <td>b급 프로그래머 월 주 소식개발관리도구 고성능 서버데이터베이스 부문</td>\n",
       "      <td>오늘의 짤방 hacking tools cheat sheet via alraees 개...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://feedproxy.google.com/~r/blogspot/aspe/~...</td>\n",
       "      <td>bㄱㅡㅂ ㅍㅡㄹㅗㄱㅡㄹㅐㅁㅓ ㅇㅝㄹ ㅈㅜ ㅅㅗㅅㅣㄱㄱㅐㅂㅏㄹㄱㅘㄴㄹㅣㄷㅗㄱㅜ ㄱㅗㅅ...</td>\n",
       "      <td>[5.189415670819082e-06, -8.260329850600101e-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34598</th>\n",
       "      <td>34598</td>\n",
       "      <td>4997</td>\n",
       "      <td>1</td>\n",
       "      <td>5e389934937bd12c10a16b9a</td>\n",
       "      <td>엔티티 매핑</td>\n",
       "      <td>들어가며 해당 글은 자바 orm 표준 프로그래밍을 정리한 글입니다 entity와 e...</td>\n",
       "      <td>java</td>\n",
       "      <td>https://kangwoojin.github.io/programing/%ec%97...</td>\n",
       "      <td>java ㅇㅔㄴㅌㅣㅌㅣ ㅁㅐㅍㅣㅇ ㄷㅡㄹㅇㅓㄱㅏㅁㅕ ㅎㅐㄷㅏㅇ ㄱㅡㄹㅇㅡㄴ ㅈㅏㅂㅏ...</td>\n",
       "      <td>[-0.0002482709398464067, 2.275143209772068e-05...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10382 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  index  label                       _id  \\\n",
       "10             10     15      0  5dacbde600c37100040ba7c4   \n",
       "386           386    413      0  5e0410563e8fe0000414586d   \n",
       "554           554    591      0  5e045c11e3e06b0004ce092e   \n",
       "644           644    684      0  5cd65b556d45ff0004343926   \n",
       "760           760    810      0  5c658301e0753928c2de3bc9   \n",
       "...           ...    ...    ...                       ...   \n",
       "34516       34516      8      1  5dcaa0cc9251e50004927a1b   \n",
       "34517       34517     10      1  5dca9fd99251e50004927a19   \n",
       "34518       34518     14      0  5dcaae1a36f8990004dd10fe   \n",
       "34545       34545    879      1  5de215daa6b34b00041ecb22   \n",
       "34598       34598   4997      1  5e389934937bd12c10a16b9a   \n",
       "\n",
       "                                                   title  \\\n",
       "10                                              about me   \n",
       "386                                                   근황   \n",
       "554                                                년 월 일   \n",
       "644                                          hello world   \n",
       "760                                                   근황   \n",
       "...                                                  ...   \n",
       "34516                   unityd tilemap 룰 타일로 타일맵 자동 연결하기   \n",
       "34517                     애자일과 소프트웨어 장인정신 코드 리뷰를 왜 해야 하나   \n",
       "34518  paper staring into the abyss an evaluation of ...   \n",
       "34545              b급 프로그래머 월 주 소식개발관리도구 고성능 서버데이터베이스 부문   \n",
       "34598                                             엔티티 매핑   \n",
       "\n",
       "                                             description         tags  \\\n",
       "10     뭐하세요 전남대학교 전자컴퓨터공학부 재학 뭐했어요 전남대학교 동아리 정보보호 준회원...          NaN   \n",
       "386    제 블로그에 들어와본지도 오래됐네요 북마크를 잘못 눌러서 제 블로그에 들어왔다가 방...          NaN   \n",
       "554    년이 시작한 지도 벌써 이틀이 지나 월 일 다른 블로그에서 년을 마무리하는 글들이 ...          NaN   \n",
       "644      hello world this is the beginning of this theme          NaN   \n",
       "760    dfest 장려상 deview 첫날 bof 시간에 croquisjs 발표자로 참가하...          NaN   \n",
       "...                                                  ...          ...   \n",
       "34516  tilemap 룰 타일로 타일맵 자동 연결하기작성 기준 버전 f지난 섹션에서는 간단...          NaN   \n",
       "34517  가끔 애자일을 구성원들에게 교육하고 애자일 코치를 통해 애자일 기법이나 절차스크럼 ...  code review   \n",
       "34518  xiangyao yu george bezerra andrew pavlo sriniv...          NaN   \n",
       "34545  오늘의 짤방 hacking tools cheat sheet via alraees 개...          NaN   \n",
       "34598  들어가며 해당 글은 자바 orm 표준 프로그래밍을 정리한 글입니다 entity와 e...         java   \n",
       "\n",
       "                                                    link  \\\n",
       "10                           https://koyo.kr/page/about/   \n",
       "386                         http://blog.hatemogi.com/143   \n",
       "554                         http://bomjun.tistory.com/11   \n",
       "644    https://000namc.github.io/blog/2013/04/22/hell...   \n",
       "760                http://blog.0xabcdef.com/100197681277   \n",
       "...                                                  ...   \n",
       "34516                     https://wergia.tistory.com/200   \n",
       "34517                      https://brunch.co.kr/@@2xm/39   \n",
       "34518               http://blog.lastmind.io/archives/903   \n",
       "34545  http://feedproxy.google.com/~r/blogspot/aspe/~...   \n",
       "34598  https://kangwoojin.github.io/programing/%ec%97...   \n",
       "\n",
       "                                                    text  \\\n",
       "10     about me ㅁㅝㅎㅏㅅㅔㅇㅛ ㅈㅓㄴㄴㅏㅁㄷㅐㅎㅏㄱㄱㅛ ㅈㅓㄴㅈㅏㅋㅓㅁㅍㅠㅌㅓㄱㅗ...   \n",
       "386    ㄱㅡㄴㅎㅘㅇ ㅈㅔ ㅂㅡㄹㄹㅗㄱㅡㅇㅔ ㄷㅡㄹㅇㅓㅇㅘㅂㅗㄴㅈㅣㄷㅗ ㅇㅗㄹㅐㄷㅙㅆㄴㅔㅇㅛ...   \n",
       "554    ㄴㅕㄴ ㅇㅝㄹ ㅇㅣㄹ ㄴㅕㄴㅇㅣ ㅅㅣㅈㅏㄱㅎㅏㄴ ㅈㅣㄷㅗ ㅂㅓㄹㅆㅓ ㅇㅣㅌㅡㄹㅇㅣ ...   \n",
       "644    hello world hello world this is the beginning ...   \n",
       "760    ㄱㅡㄴㅎㅘㅇ dfest ㅈㅏㅇㄹㅕㅅㅏㅇ deview ㅊㅓㅅㄴㅏㄹ bof ㅅㅣㄱㅏㄴㅇ...   \n",
       "...                                                  ...   \n",
       "34516  unityd tilemap ㄹㅜㄹ ㅌㅏㅇㅣㄹㄹㅗ ㅌㅏㅇㅣㄹㅁㅐㅂ ㅈㅏㄷㅗㅇ ㅇㅕㄴㄱ...   \n",
       "34517  code review ㅇㅐㅈㅏㅇㅣㄹㄱㅘ ㅅㅗㅍㅡㅌㅡㅇㅞㅇㅓ ㅈㅏㅇㅇㅣㄴㅈㅓㅇㅅㅣㄴ ...   \n",
       "34518  paper staring into the abyss an evaluation of ...   \n",
       "34545  bㄱㅡㅂ ㅍㅡㄹㅗㄱㅡㄹㅐㅁㅓ ㅇㅝㄹ ㅈㅜ ㅅㅗㅅㅣㄱㄱㅐㅂㅏㄹㄱㅘㄴㄹㅣㄷㅗㄱㅜ ㄱㅗㅅ...   \n",
       "34598  java ㅇㅔㄴㅌㅣㅌㅣ ㅁㅐㅍㅣㅇ ㄷㅡㄹㅇㅓㄱㅏㅁㅕ ㅎㅐㄷㅏㅇ ㄱㅡㄹㅇㅡㄴ ㅈㅏㅂㅏ...   \n",
       "\n",
       "                                                  vector  \n",
       "10     [-1.5842538362319048e-05, -9.35396417931077e-0...  \n",
       "386    [-2.0547285947197285e-05, -0.00020704209594607...  \n",
       "554    [0.0001649544182227045, -0.0002266320312898002...  \n",
       "644    [-6.551726586291228e-05, 1.8461513801329684e-0...  \n",
       "760    [-0.00017004047499953728, 5.046020768614571e-0...  \n",
       "...                                                  ...  \n",
       "34516  [4.8495559737175984e-05, -4.197198774948317e-0...  \n",
       "34517  [-4.8762879867519425e-05, 1.4807322986598593e-...  \n",
       "34518  [-2.1099355319343087e-05, -0.00011323287578040...  \n",
       "34545  [5.189415670819082e-06, -8.260329850600101e-05...  \n",
       "34598  [-0.0002482709398464067, 2.275143209772068e-05...  \n",
       "\n",
       "[10382 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 162       \n",
      "=================================================================\n",
      "Total params: 38,342\n",
      "Trainable params: 38,342\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6259 samples, validate on 696 samples\n",
      "Epoch 1/8\n",
      "4600/6259 [=====================>........] - ETA: 0s - loss: 0.3896 - acc: 0.8165 - f1_m: 0.8436 - precision_m: 0.7304 - recall_m: 1.0000\n",
      "Epoch 00001: val_acc improved from -inf to 0.84914, saving model to ./model/200218\n",
      "INFO:tensorflow:Assets written to: ./model/200218/assets\n",
      "6259/6259 [==============================] - 2s 246us/sample - loss: 0.3776 - acc: 0.8265 - f1_m: 0.8447 - precision_m: 0.7323 - recall_m: 1.0000 - val_loss: 0.3298 - val_acc: 0.8491 - val_f1_m: 0.8518 - val_precision_m: 0.7424 - val_recall_m: 1.0000\n",
      "Epoch 2/8\n",
      "4800/6259 [======================>.......] - ETA: 0s - loss: 0.3339 - acc: 0.8512 - f1_m: 0.8438 - precision_m: 0.7308 - recall_m: 1.0000\n",
      "Epoch 00002: val_acc improved from 0.84914 to 0.86782, saving model to ./model/200218\n",
      "INFO:tensorflow:Assets written to: ./model/200218/assets\n",
      "6259/6259 [==============================] - 1s 101us/sample - loss: 0.3365 - acc: 0.8501 - f1_m: 0.8442 - precision_m: 0.7315 - recall_m: 1.0000 - val_loss: 0.3189 - val_acc: 0.8678 - val_f1_m: 0.8518 - val_precision_m: 0.7424 - val_recall_m: 1.0000\n",
      "Epoch 3/8\n",
      "6200/6259 [============================>.] - ETA: 0s - loss: 0.3206 - acc: 0.8552 - f1_m: 0.8454 - precision_m: 0.7331 - recall_m: 1.0000\n",
      "Epoch 00003: val_acc did not improve from 0.86782\n",
      "6259/6259 [==============================] - 0s 29us/sample - loss: 0.3222 - acc: 0.8544 - f1_m: 0.8442 - precision_m: 0.7314 - recall_m: 1.0000 - val_loss: 0.3202 - val_acc: 0.8635 - val_f1_m: 0.8518 - val_precision_m: 0.7424 - val_recall_m: 1.0000\n",
      "Epoch 4/8\n",
      "5100/6259 [=======================>......] - ETA: 0s - loss: 0.3071 - acc: 0.8620 - f1_m: 0.8478 - precision_m: 0.7367 - recall_m: 1.0000\n",
      "Epoch 00004: val_acc did not improve from 0.86782\n",
      "6259/6259 [==============================] - 0s 25us/sample - loss: 0.3124 - acc: 0.8580 - f1_m: 0.8449 - precision_m: 0.7323 - recall_m: 1.0000 - val_loss: 0.3025 - val_acc: 0.8664 - val_f1_m: 0.8518 - val_precision_m: 0.7424 - val_recall_m: 1.0000\n",
      "Epoch 5/8\n",
      "4700/6259 [=====================>........] - ETA: 0s - loss: 0.3020 - acc: 0.8655 - f1_m: 0.8477 - precision_m: 0.7368 - recall_m: 1.0000\n",
      "Epoch 00005: val_acc improved from 0.86782 to 0.87787, saving model to ./model/200218\n",
      "INFO:tensorflow:Assets written to: ./model/200218/assets\n",
      "6259/6259 [==============================] - 1s 107us/sample - loss: 0.3045 - acc: 0.8653 - f1_m: 0.8449 - precision_m: 0.7326 - recall_m: 1.0000 - val_loss: 0.2967 - val_acc: 0.8779 - val_f1_m: 0.8518 - val_precision_m: 0.7424 - val_recall_m: 1.0000\n",
      "Epoch 6/8\n",
      "5300/6259 [========================>.....] - ETA: 0s - loss: 0.2982 - acc: 0.8717 - f1_m: 0.8442 - precision_m: 0.7315 - recall_m: 1.0000\n",
      "Epoch 00006: val_acc did not improve from 0.87787\n",
      "6259/6259 [==============================] - 0s 26us/sample - loss: 0.2987 - acc: 0.8707 - f1_m: 0.8443 - precision_m: 0.7319 - recall_m: 1.0000 - val_loss: 0.3003 - val_acc: 0.8693 - val_f1_m: 0.8518 - val_precision_m: 0.7424 - val_recall_m: 1.0000\n",
      "Epoch 7/8\n",
      "5100/6259 [=======================>......] - ETA: 0s - loss: 0.2819 - acc: 0.8749 - f1_m: 0.8472 - precision_m: 0.7359 - recall_m: 1.0000\n",
      "Epoch 00007: val_acc did not improve from 0.87787\n",
      "6259/6259 [==============================] - 0s 33us/sample - loss: 0.2883 - acc: 0.8717 - f1_m: 0.8447 - precision_m: 0.7323 - recall_m: 1.0000 - val_loss: 0.3127 - val_acc: 0.8549 - val_f1_m: 0.8518 - val_precision_m: 0.7424 - val_recall_m: 1.0000\n",
      "Epoch 8/8\n",
      "4200/6259 [===================>..........] - ETA: 0s - loss: 0.2823 - acc: 0.8771 - f1_m: 0.8469 - precision_m: 0.7355 - recall_m: 1.0000\n",
      "Epoch 00008: val_acc did not improve from 0.87787\n",
      "6259/6259 [==============================] - 0s 29us/sample - loss: 0.2802 - acc: 0.8779 - f1_m: 0.8450 - precision_m: 0.7327 - recall_m: 1.0000 - val_loss: 0.3009 - val_acc: 0.8520 - val_f1_m: 0.8518 - val_precision_m: 0.7424 - val_recall_m: 1.0000\n",
      "loss : 0.29527061357485473\n",
      "accuracy : 0.8707324266433716\n",
      "f1_score : 0.8475756645202637\n",
      "precision : 0.7391010522842407\n",
      "recall : 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = cf.train(docs,\n",
    "                 checkpoint_path='./model/200218',\n",
    "                 epochs=8,\n",
    "                )\n",
    "cf.showHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devbog_classifier",
   "language": "python",
   "name": "devbog_classifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
